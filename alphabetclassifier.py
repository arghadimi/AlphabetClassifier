# -*- coding: utf-8 -*-
"""AlphabetClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10AbTeImgAPRQwG8BuMHXUlcu9YMS5hn-

Deep neural netwroks are felxible function estimators that are able to approximate the relation between inputs and outputs given an adequate training dataset. 
For instance such a network can be used to recognize the contents of a image inputs. One example of this data can be recognition of the characters from there pictures written by different fonts. 
In thi project I deployed a convolutional neural network that recognize the character written in the given image inputs.

The dataset is loaded as a .pickle file on my Google drive. Thus it is required to mount on your drive, you can download the data files from the links below:

y_data: https://drive.google.com/file/d/13R9uk38FY6hXJAv2-zLA9H_AsYsjJvGz/view?usp=sharing 

x_data: https://drive.google.com/file/d/1QET-_s47bnGnTK653_dYy1LQB0MgN-m0/view?usp=sharing
"""

from google.colab import drive

drive.mount('/content/gdrive')
root_path = 'gdrive/My Drive/Colab_Notebooks_new/'  #change dir to your project folder

"""Define the dataset class:"""

import pickle
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import Dataset, DataLoader

def one_hot_alphabets(c):
    idx=ord(c)-ord('A')
    y=torch.zeros(1,26)
    y[0,idx]=1
    return y
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') 

#!dir gdrive/"My Drive"/Colab_Notebooks_new/
#!ls
class AlphabetData(Dataset):
    
    def __init__(self):
        with open("gdrive/My Drive/DeepLearningProjects/Xdata.pkl","rb") as f:
            self.x=pickle.load(f)
        
        with open("gdrive/My Drive/DeepLearningProjects/Ydata.pkl","rb") as f:
            self.y=pickle.load(f).type(torch.int64)
        self.n_samples = self.y.shape[0]
    
    def __getitem__(self,index):
        return self.x[index], self.y[index]
    def __len__(self):
        return self.n_samples

"""Defining the convolutional model"""

# Model
n_features=32*32

class DeepModel(nn.Module):
    def __init__(self, num_classes):
        super(DeepModel,self).__init__()
        self.conv1  = nn.Conv2d(1,32,5,padding='same').to(device)
        self.pool   = nn.MaxPool2d(2, stride=2)
        self.conv2  = nn.Conv2d(32,32,5,padding='same').to(device)
        self.conv3  = nn.Conv2d(32,16,5,padding='same').to(device)
        self.linear1 = nn.Linear(256,128).to(device)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(128,128).to(device)
        self.linear3 = nn.Linear(128,64).to(device)
        self.linear4 = nn.Linear(64,num_classes).to(device)
        
    def forward(self,x):
        x = x.view(-1,1,32,32)
        z = self.pool(self.relu(self.conv1(x)))
        z = self.pool(self.relu(self.conv2(z)))
        z = self.pool(self.relu(self.conv3(z)))
        z = self.linear1(z.view(-1,z.shape[1]*z.shape[2]*z.shape[3]))
        z = self.relu(z)
        y_pred = self.linear2(z)
        return y_pred
    
model=DeepModel(26)

"""Training the model:"""

# loss and optimizer
lr=0.01
loss_func=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters())
batch_size=400
num_epochs = 1000 

# Data loader
dataset=AlphabetData()
dataloader=DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)

# training loop


for epoch in range(num_epochs):
    
    for i, (inputs,labels) in enumerate(dataloader):
        inputs = inputs.to(device)
        labels=labels.to(device)  
        y_predicted = model(inputs)  
        loss = loss_func(y_predicted,labels)
        
        loss.backward()
        
        optimizer.step()
        optimizer.zero_grad()
    
    if (epoch+1) % 10 ==0:
        with torch.no_grad():
          _,pred = torch.max(y_predicted,1)
          acc=100*sum(labels==pred)/batch_size
        print(f'epoch: {epoch+1}, loss={loss.item():.4f}, accuracy= % {acc}')

"""Save the model in for later usage
The link for downloading the model:
https://drive.google.com/file/d/1bPIpFnFLhfRl9HUMEQspNiEEoTyYNSXS/view?usp=sharing 
"""

PATH='gdrive/My Drive/DeepLearningProjects/LetterRecongnitionModel'
torch.save(model.state_dict(), PATH)

"""Load the saved model instead of training"""

model.load_state_dict(torch.load(PATH))

# %% Testing
x=dataset.x
y=dataset.y
with torch.no_grad():
    n_correct = 0
    n_samples = 0
    for i in range(x.shape[0]):
        x_=x[i,:,:].view(-1,n_features).to(device)
        y_=y[i]
        y_pred=model(x_)
        _,pred = torch.max(y_pred,1)
        n_samples += 1
        n_correct += (pred==y_).sum().item()
    acc= 100.0*n_correct/n_samples
    print(acc)

with torch.no_grad():
    n_correct = 0
    n_samples = 0
    for i in np.random.choice(x.shape[0],100):
        plt.imshow(x[i,:,:])
        x_=x[i,:,:].view(-1,n_features).to(device)
        y_=y[i]
        y_pred=model(x_)
        _,pred = torch.max(y_pred,1)
        n_samples += 1
        n_correct += (pred==y_).sum().item()
        plt.title("pred:"+chr(pred+ord('A'))+ ", True:"+chr(y_+ord('A')))
        plt.show()
        plt.savefig('sample'+str(i)+chr(y_+ord('A')))
    acc= 100.0*n_correct/n_samples
    print('The network accuracy: %'+str(acc))

